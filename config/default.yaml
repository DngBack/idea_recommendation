# =============================================
# Idea Generator â€“ Default Configuration
# =============================================
# Override any of these via CLI flags, e.g.:
#   idea-generator --topic-file topic.md --model gpt-4o --max-generations 10

# LLM model to use for idea generation
# Examples: gpt-4o-2024-05-13, gpt-5.2 (thinking), gpt-5.2-pro, claude-3-5-sonnet-20241022
model: "gpt-5.2"

# Maximum number of ideas to generate in one run
max_generations: 3

# Number of reflection / refinement rounds per idea
num_reflections: 5

# Directory for output files (relative to CWD)
output_dir: "output"

# Validate each idea against JSON schema before accepting it
validate: true

# Enable novelty scoring (uses an extra LLM call per idea)
novelty_scoring: false

# Model to use for novelty scoring (empty = same as `model`)
novelty_model: ""

# How often to write a checkpoint (every N ideas)
checkpoint_interval: 1

# Enable the arXiv search tool alongside Semantic Scholar
arxiv_enabled: true

# Enable PubMed search (biology, medicine, NLP)
pubmed_enabled: false

# Enable OpenAlex search (broad coverage, DOI, citations)
openalex_enabled: false

# Resume from a previous checkpoint (set to true or use --resume flag)
resume: false

# Override the system prompt entirely (leave empty to use the built-in prompt)
system_prompt_override: ""

# Research pipeline (4-phase): literature review -> hypotheses -> direction -> experiment plan
# Use --pipeline to run full pipeline, or --phase <name> with --from-* for a single phase
pipeline_mode: false
research_pipeline:
  literature_reflections: 8
  direction_reflections: 5
  max_hypotheses: 10
